\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{torchvision}
Py{T}orch {V}ision {M}odels.
\newblock \url{{https://pytorch.org/vision/stable/models.html}}.
\newblock Accessed: 2021-10-01.

\bibitem{swincode}
{GitHub} repository: Swin transformer.
\newblock \url{{https://github.com/microsoft/Swin-Transformer}}, 2021.

\bibitem{swindetcode}
{GitHub} repository: Swin transformer for object detection.
\newblock
  \url{https://github.com/SwinTransformer/Swin-Transformer-Object-Detection},
  2021.

\bibitem{convmixer}
Anonymous.
\newblock Patches are all you need?
\newblock {\em Openreview}, 2021.

\bibitem{Ba2016}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock {\em arXiv:1607.06450}, 2016.

\bibitem{Bao2021}
Hangbo Bao, Li Dong, and Furu Wei.
\newblock {BEiT}: {BERT} pre-training of image transformers.
\newblock {\em arXiv:2106.08254}, 2021.

\bibitem{bello2021revisiting}
Irwan Bello, William Fedus, Xianzhi Du, Ekin~Dogus Cubuk, Aravind Srinivas,
  Tsung-Yi Lin, Jonathon Shlens, and Barret Zoph.
\newblock Revisiting resnets: Improved training and scaling strategies.
\newblock {\em NeurIPS}, 2021.

\bibitem{bello2019attention}
Irwan Bello, Barret Zoph, Ashish Vaswani, Jonathon Shlens, and Quoc~V Le.
\newblock Attention augmented convolutional networks.
\newblock In {\em ICCV}, 2019.

\bibitem{Cai2018}
Zhaowei Cai and Nuno Vasconcelos.
\newblock {Cascade R-CNN}: Delving into high quality object detection.
\newblock In {\em CVPR}, 2018.

\bibitem{mmdetection}
Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li,
  Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, Zheng Zhang, Dazhi Cheng,
  Chenchen Zhu, Tianheng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu,
  Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, Chen~Change Loy, and
  Dahua Lin.
\newblock {MMDetection}: Open mmlab detection toolbox and benchmark.
\newblock {\em arXiv:1906.07155}, 2019.

\bibitem{Chollet2017}
Fran{\c{c}}ois Chollet.
\newblock Xception: Deep learning with depthwise separable convolutions.
\newblock In {\em CVPR}, 2017.

\bibitem{Clark2020}
Kevin Clark, Minh-Thang Luong, Quoc~V Le, and Christopher~D Manning.
\newblock {ELECTRA}: Pre-training text encoders as discriminators rather than
  generators.
\newblock In {\em ICLR}, 2020.

\bibitem{mmseg2020}
MMSegmentation contributors.
\newblock {MMSegmentation}: Openmmlab semantic segmentation toolbox and
  benchmark.
\newblock \url{https://github.com/open-mmlab/mmsegmentation}, 2020.

\bibitem{Cubuk2020}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em CVPR Workshops}, 2020.

\bibitem{dai2021coatnet}
Zihang Dai, Hanxiao Liu, Quoc~V Le, and Mingxing Tan.
\newblock Coatnet: Marrying convolution and attention for all data sizes.
\newblock {\em NeurIPS}, 2021.

\bibitem{d2021convit}
St{\'e}phane d'Ascoli, Hugo Touvron, Matthew Leavitt, Ari Morcos, Giulio
  Biroli, and Levent Sagun.
\newblock {ConViT}: Improving vision transformers with soft convolutional
  inductive biases.
\newblock {\em ICML}, 2021.

\bibitem{Deng2009}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock {ImageNet: A large-scale hierarchical image database}.
\newblock In {\em CVPR}, 2009.

\bibitem{Devlin2019}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em NAACL}, 2019.

\bibitem{dollar2010fastest}
Piotr Doll{\'a}r, Serge Belongie, and Pietro Perona.
\newblock The fastest pedestrian detector in the west.
\newblock In {\em BMVC}, 2010.

\bibitem{Dosovitskiy2021}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{fan2021multiscale}
Haoqi Fan, Bo Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra
  Malik, and Christoph Feichtenhofer.
\newblock Multiscale vision transformers.
\newblock {\em ICCV}, 2021.

\bibitem{clpytorch}
Vitaly Fedyunin.
\newblock Tutorial: {C}hannel last memory format in {P}y{T}orch.
\newblock
  \url{https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html},
  2021.
\newblock Accessed: 2021-10-01.

\bibitem{Girshick2015}
Ross Girshick.
\newblock {Fast R-CNN}.
\newblock In {\em ICCV}, 2015.

\bibitem{Girshick2014}
Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik.
\newblock Rich feature hierarchies for accurate object detection and semantic
  segmentation.
\newblock In {\em CVPR}, 2014.

\bibitem{han2021demystifying}
Qi Han, Zejia Fan, Qi Dai, Lei Sun, Ming-Ming Cheng, Jiaying Liu, and Jingdong
  Wang.
\newblock Demystifying local vision transformer: Sparse connectivity, weight
  sharing, and dynamic weight.
\newblock {\em arXiv:2106.04263}, 2021.

\bibitem{he2021masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock {\em arXiv:2111.06377}, 2021.

\bibitem{He2017}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock {Mask R-CNN}.
\newblock In {\em ICCV}, 2017.

\bibitem{He2016}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{He2016a}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Identity mappings in deep residual networks.
\newblock In {\em ECCV}, 2016.

\bibitem{hendrycks2021many}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan
  Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In {\em ICCV}, 2021.

\bibitem{hendrycks2018benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In {\em ICLR}, 2018.

\bibitem{Hendrycks2016}
Dan Hendrycks and Kevin Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock {\em arXiv:1606.08415}, 2016.

\bibitem{hendrycks2021natural}
Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song.
\newblock Natural adversarial examples.
\newblock In {\em CVPR}, 2021.

\bibitem{Howard2017}
Andrew~G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang,
  Tobias Weyand, Marco Andreetto, and Hartwig Adam.
\newblock {MobileNets}: Efficient convolutional neural networks for mobile
  vision applications.
\newblock {\em arXiv:1704.04861}, 2017.

\bibitem{hu2018squeeze}
Jie Hu, Li Shen, and Gang Sun.
\newblock Squeeze-and-excitation networks.
\newblock In {\em CVPR}, 2018.

\bibitem{Huang2017}
Gao Huang, Zhuang Liu, Laurens van~der Maaten, and Kilian~Q Weinberger.
\newblock Densely connected convolutional networks.
\newblock In {\em CVPR}, 2017.

\bibitem{Huang2016deep}
Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian~Q Weinberger.
\newblock Deep networks with stochastic depth.
\newblock In {\em ECCV}, 2016.

\bibitem{Ioffe2017}
Sergey Ioffe.
\newblock Batch renormalization: Towards reducing minibatch dependence in
  batch-normalized models.
\newblock In {\em NeurIPS}, 2017.

\bibitem{Kolesnikov2020}
Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung,
  Sylvain Gelly, and Neil Houlsby.
\newblock {Big Transfer (BiT)}: General visual representation learning.
\newblock In {\em ECCV}, 2020.

\bibitem{Krizhevsky2012}
Alex Krizhevsky, Ilya Sutskever, and Geoff Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em NeurIPS}, 2012.

\bibitem{Lavin2016FastAF}
Andrew Lavin and Scott Gray.
\newblock Fast algorithms for convolutional neural networks.
\newblock In {\em CVPR}, 2016.

\bibitem{LeCun1989}
Yann LeCun, Bernhard Boser, John~S Denker, Donnie Henderson, Richard~E Howard,
  Wayne Hubbard, and Lawrence~D Jackel.
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock {\em Neural computation}, 1989.

\bibitem{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, Patrick Haffner, et~al.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 1998.

\bibitem{Lin2014}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock {Microsoft COCO: Common objects in context}.
\newblock In {\em ECCV}. 2014.

\bibitem{Liu2021swin}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock 2021.

\bibitem{Loshchilov2019}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em ICLR}, 2019.

\bibitem{mao2021towards}
Xiaofeng Mao, Gege Qi, Yuefeng Chen, Xiaodan Li, Ranjie Duan, Shaokai Ye, Yuan
  He, and Hui Xue.
\newblock Towards robust vision transformer.
\newblock {\em arXiv preprint arXiv:2105.07926}, 2021.

\bibitem{mintun2021interaction}
Eric Mintun, Alexander Kirillov, and Saining Xie.
\newblock On interaction between augmentations and corruptions in natural
  corruption robustness.
\newblock {\em NeurIPS}, 2021.

\bibitem{Nair2010}
Vinod Nair and Geoffrey~E Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In {\em ICML}, 2010.

\bibitem{Paszke2019}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock {PyTorch: An imperative style, high-performance deep learning
  library}.
\newblock In {\em NeurIPS}, 2019.

\bibitem{Polyak1992}
Boris~T Polyak and Anatoli~B Juditsky.
\newblock Acceleration of stochastic approximation by averaging.
\newblock {\em SIAM Journal on Control and Optimization}, 1992.

\bibitem{Radford2019}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem{Radosavovic2019network}
Ilija Radosavovic, Justin Johnson, Saining Xie, Wan-Yen Lo, and Piotr
  Doll{\'a}r.
\newblock On network design spaces for visual recognition.
\newblock In {\em ICCV}, 2019.

\bibitem{Radosavovic2020designing}
Ilija Radosavovic, Raj~Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr
  Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In {\em CVPR}, 2020.

\bibitem{ramachandran2019stand}
Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya,
  and Jonathon Shlens.
\newblock Stand-alone self-attention in vision models.
\newblock {\em NeurIPS}, 2019.

\bibitem{rao2021global}
Yongming Rao, Wenliang Zhao, Zheng Zhu, Jiwen Lu, and Jie Zhou.
\newblock Global filter networks for image classification.
\newblock {\em NeurIPS}, 2021.

\bibitem{Ren2015}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock {Faster R-CNN}: Towards real-time object detection with region
  proposal networks.
\newblock In {\em NeurIPS}, 2015.

\bibitem{rowley1998neural}
Henry~A Rowley, Shumeet Baluja, and Takeo Kanade.
\newblock Neural network-based face detection.
\newblock {\em TPAMI}, 1998.

\bibitem{Russakovsky2015}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock {\em IJCV}, 2015.

\bibitem{Salimans2016}
Tim Salimans and Diederik~P Kingma.
\newblock Weight normalization: A simple reparameterization to accelerate
  training of deep neural networks.
\newblock In {\em NeurIPS}, 2016.

\bibitem{Sandler2018}
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh
  Chen.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In {\em CVPR}, 2018.

\bibitem{Sermanet2014}
Pierre Sermanet, David Eigen, Xiang Zhang, Michael Mathieu, Rob Fergus, and
  Yann LeCun.
\newblock Overfeat: Integrated recognition, localization and detection using
  convolutional networks.
\newblock In {\em ICLR}, 2014.

\bibitem{sermanet2013pedestrian}
Pierre Sermanet, Koray Kavukcuoglu, Soumith Chintala, and Yann LeCun.
\newblock Pedestrian detection with unsupervised multi-stage feature learning.
\newblock In {\em CVPR}, 2013.

\bibitem{Simonyan2014}
Karen Simonyan and Andrew Zisserman.
\newblock Two-stream convolutional networks for action recognition in videos.
\newblock In {\em NeurIPS}, 2014.

\bibitem{Simonyan2015}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In {\em ICLR}, 2015.

\bibitem{srinivas2021bottleneck}
Aravind Srinivas, Tsung-Yi Lin, Niki Parmar, Jonathon Shlens, Pieter Abbeel,
  and Ashish Vaswani.
\newblock Bottleneck transformers for visual recognition.
\newblock In {\em CVPR}, 2021.

\bibitem{steiner2021train}
Andreas Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob
  Uszkoreit, and Lucas Beyer.
\newblock How to train your vit? data, augmentation, and regularization in
  vision transformers.
\newblock {\em arXiv preprint arXiv:2106.10270}, 2021.

\bibitem{Szegedy2015}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
  Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In {\em CVPR}, 2015.

\bibitem{Szegedy2016a}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and
  Zbigniew Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In {\em CVPR}, 2016.

\bibitem{tan2019mnasnet}
Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew
  Howard, and Quoc~V Le.
\newblock Mnasnet: Platform-aware neural architecture search for mobile.
\newblock In {\em CVPR}, 2019.

\bibitem{Tan2019efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In {\em ICML}, 2019.

\bibitem{tan2021efficientnetv2}
Mingxing Tan and Quoc Le.
\newblock Efficientnetv2: Smaller models and faster training.
\newblock In {\em ICML}, 2021.

\bibitem{Touvron2020}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock {\em arXiv:2012.12877}, 2020.

\bibitem{Touvron2021GoingDW}
Hugo Touvron, Matthieu Cord, Alexandre Sablayrolles, Gabriel Synnaeve, and
  Herv{\'e} J{\'e}gou.
\newblock Going deeper with image transformers.
\newblock {\em ICCV}, 2021.

\bibitem{Ulyanov2016}
Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky.
\newblock Instance normalization: The missing ingredient for fast stylization.
\newblock {\em arXiv:1607.08022}, 2016.

\bibitem{vaillant1994original}
R{\'e}gis Vaillant, Christophe Monrocq, and Yann Le~Cun.
\newblock Original approach for the localisation of objects in images.
\newblock {\em Vision, Image and Signal Processing}, 1994.

\bibitem{Vaswani2017}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{wang2019learning}
Haohan Wang, Songwei Ge, Eric~P Xing, and Zachary~C Lipton.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock {\em NeurIPS}, 2019.

\bibitem{Wang2018}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In {\em CVPR}, 2018.

\bibitem{rw2019timm}
Ross Wightman.
\newblock {GitHub} repository: Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem{Wightman2021resnet}
Ross Wightman, Hugo Touvron, and Herv{\'e} J{\'e}gou.
\newblock Resnet strikes back: An improved training procedure in timm.
\newblock {\em arXiv:2110.00476}, 2021.

\bibitem{wu2021cvt}
Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, and Lei
  Zhang.
\newblock Cvt: Introducing convolutions to vision transformers.
\newblock {\em ICCV}, 2021.

\bibitem{Wu2018}
Yuxin Wu and Kaiming He.
\newblock Group normalization.
\newblock In {\em ECCV}, 2018.

\bibitem{wu2021rethinking}
Yuxin Wu and Justin Johnson.
\newblock Rethinking "batch" in batchnorm.
\newblock {\em arXiv:2105.07576}, 2021.

\bibitem{Xiao2018}
Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun.
\newblock Unified perceptual parsing for scene understanding.
\newblock In {\em ECCV}, 2018.

\bibitem{Xiao2021}
Tete Xiao, Mannat Singh, Eric Mintun, Trevor Darrell, Piotr Doll{\'a}r, and
  Ross Girshick.
\newblock Early convolutions help transformers see better.
\newblock In {\em NeurIPS}, 2021.

\bibitem{Xie2017}
Saining Xie, Ross Girshick, Piotr Doll{\'a}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In {\em CVPR}, 2017.

\bibitem{xu2021co}
Weijian Xu, Yifan Xu, Tyler Chang, and Zhuowen Tu.
\newblock Co-scale conv-attentional image transformers.
\newblock {\em ICCV}, 2021.

\bibitem{Yun2019}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em ICCV}, 2019.

\bibitem{Zhang2018a}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In {\em ICLR}, 2018.

\bibitem{Zhong2020}
Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang.
\newblock Random erasing data augmentation.
\newblock In {\em AAAI}, 2020.

\bibitem{Zhou2019}
Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso,
  and Antonio Torralba.
\newblock Semantic understanding of scenes through the {ADE20K} dataset.
\newblock {\em IJCV}, 2019.

\end{thebibliography}

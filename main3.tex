%% thesis.tex 2014/04/11
%
% Based on sample files of unknown authorship.
%
% The Current Maintainer of this work is Paul Vojta.

\documentclass{ucbthesis}

\usepackage{biblatex}
\usepackage{rotating} % provides sidewaystable and sidewaysfigure
\usepackage{url}
\usepackage{wrapfig}
\usepackage{subcaption}

\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{float}
\usepackage{hyperref}  

% convnext

\newlength\savewidth\newcommand\shline{\noalign{\global\savewidth\arrayrulewidth
  \global\arrayrulewidth 1pt}\hline\noalign{\global\arrayrulewidth\savewidth}}
\newcommand{\tablestyle}[2]{\setlength{\tabcolsep}{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}
\renewcommand{\paragraph}[1]{\vspace{1.25mm}\noindent\textbf{#1}}
\newcommand\blfootnote[1]{\begingroup\renewcommand\thefootnote{}\footnote{#1}\addtocounter{footnote}{-1}\endgroup}

\newcolumntype{x}[1]{>{\centering\arraybackslash}p{#1pt}}
\newcolumntype{y}[1]{>{\raggedright\arraybackslash}p{#1pt}}
\newcolumntype{z}[1]{>{\raggedleft\arraybackslash}p{#1pt}}

\newcommand{\dt}[1]{\fontsize{8pt}{.1em}\selectfont \emph{#1}}
\makeatletter\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}
	{.5em \@plus1ex \@minus.2ex}{-.5em}{\normalfont\normalsize\bfseries}}\makeatother

\newcommand{\app}{\raise.17ex\hbox{$\scriptstyle\sim$}}
\newcommand{\mypm}[1]{\color{gray}{\tiny{$\pm$#1}}}
\newcommand{\x}{{\times}}
\definecolor{deemph}{gray}{0.6}
\newcommand{\gc}[1]{\textcolor{deemph}{#1}}
\definecolor{baselinecolor}{gray}{.92}
\newcommand{\baseline}[1]{\cellcolor{baselinecolor}{#1}}
\newcommand{\authorskip}{\hspace{2.5mm}}

\usepackage{graphicx, amsmath, amssymb, caption, subcaption, multirow, overpic}
% \usepackage[table]{xcolor}
\usepackage{booktabs}
% \usepackage[american]{babel}
\usepackage{textpos}
\usepackage{marvosym}
\usepackage{wasysym}

\usepackage{color}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{multirow}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{tabulary,multirow,overpic,xcolor}
\usepackage{makecell}
\usepackage{colortbl}
\usepackage{bm}
\usepackage{t1enc}
\usepackage{lipsum}  

\definecolor{convcolor}{HTML}{412F8A}
\definecolor{resnetcolor}{HTML}{8DA0CB}
\definecolor{vitcolor}{HTML}{fc8e62}


\newcommand{\convcolor}[1]{\textcolor{convcolor}{#1}}
\newcommand{\vitcolor}[1]{\textcolor{vitcolor}{#1}}
\newcommand{\cnn}{ConvNeXt}


\newcommand{\vb}{\vitcolor{$\mathbf{\circ}$\,}}
\newcommand{\cb}{\convcolor{$\bullet$\,}}
\newcommand{\gr}{\rowcolor[gray]{.95}}


% added from https://stackoverflow.com/questions/3282319/correct-way-to-define-macros-etc-ie-in-latex
\usepackage{xspace}

% Add a period to the end of an abbreviation unless there's one
% already, then \xspace.
\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}
\makeatother



% \renewcommand{\cite}{\citep}
% \renewcommand{\cite}{\citet}


% To compile this file, run "latex thesis", then "biber thesis"
% (or "bibtex thesis", if the output from latex asks for that instead),
% and then "latex thesis" (without the quotes in each case).

% Double spacing, if you want it.  Do not use for the final copy.
% \def\dsp{\def\baselinestretch{2.0}\large\normalsize}
% \dsp

% If the Grad. Division insists that the first paragraph of a section
% be indented (like the others), then include this line:
% \usepackage{indentfirst}

\addtolength{\abovecaptionskip}{\baselineskip}

% \newtheorem{theorem}{Jibberish} 
% \bibliography{ref.bib}
% https://tex.stackexchange.com/questions/226137/bibliographystyle-invalid-what-am-i-doing-wrong-in-my-latex-file-or-bibtex-file
\addbibresource{ref.bib}


\hyphenation{mar-gin-al-ia}
\hyphenation{bra-va-do}

\begin{document}

% Declarations for Front Matter

\title{Efficient and Scalable Neural Architectures for Visual Recognition}
\author{Zhuang Liu}
\degreesemester{Summer}
\degreeyear{2022}
\degree{Doctor of Philosophy}
\chair{Professor Trevor Darrell}
\othermembers{Professor Joseph Gonzalez  \\
  Professor Jiantao Jiao \\
  Dr. Saining Xie}
% For a co-chair who is subordinate to the \chair listed above
% \cochair{Professor Benedict Francis Pope}
% For two co-chairs of equal standing (do not use \chair with this one)
% \cochairs{Professor Richard Francis Sony}{Professor Benedict Francis Pope}
\numberofmembers{4}
% Previous degrees are no longer to be listed on the title page.
% \prevdegrees{B.A. (University of Northern South Dakota at Hoople) 1978 \\
%   M.S. (Ed's School of Quantum Mechanics and Muffler Repair) 1989}
\field{Computer Science}
% Designated Emphasis -- this is optional, and rare
% \emphasis{Colloidal Telemetry}
% This is optional, and rare
% \jointinstitution{University of Western Maryland}
% This is optional (default is Berkeley)
% \campus{Berkeley}

% For a masters thesis, replace the above \documentclass line with
% \documentclass[masters]{ucbthesis}
% This affects the title and approval pages, which by default calls this
% document a "dissertation", not a "thesis".

\maketitle
% Delete (or comment out) the \approvalpage line for the final version.
% \approvalpage
\copyrightpage

\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}

\include{abstract}

\begin{frontmatter}

\begin{dedication}
\null\vfil
\begin{center}
To my parents, Lilin Miao and Qing Liu
% To Ossie Bernosky\\\vspace{12pt}
% And exposition? Of go. No upstairs do fingering. Or obstructive, or purposeful.
% In the glitter. For so talented. Which is confines cocoa accomplished.
% Masterpiece as devoted. My primal the narcotic. For cine? To by recollection
% bleeding. That calf are infant. In clause. Be a popularly. A as midnight
% transcript alike. Washable an acre. To canned, silence in foreign.
\end{center}
\vfil\null
\end{dedication}

% You can delete the \clearpage lines if you don't want these to start on
% separate pages.

\tableofcontents
\clearpage
\listoffigures
\clearpage
\listoftables

\begin{acknowledgements}
I want to thank all people who have helped or supported me during my Ph.D. journey. First, I would like to express my sincere gratitude to my advisor Prof. Trevor Darrell. Trevor has continued to guide me on how to do quality and impactful research, while also giving me the freedom to work on research topics that I'm interested in. His advices on both high-level research directions and execution plans have always been helpful. He would not withhold critical opinions either, which pushed me to distill and refine my work until it is above the high standard he sets and can withstand challenges. Of course, the help and lessons from Trevor are more than on research. When I was having a hard time getting my papers accepted, Trevor always expressed his strongest support and reassured me the value of my research. The career advices from him are also invaluable. I would also like to thank Prof. Joseph Gonzalez, Prof. Jiantao Jiao, and Dr. Saining Xie for being on my dissertation committee, who gave me lots of useful advices in delivering my dissertation talk and writing this thesis.

I was fortunate enough to have other excellent mentors during my Ph.D. study. I would like to thank Vladlen Koltun for supervising me during my internship at Intel Labs, where I worked with wonderful colleagues John Lambert and Ozan Sener. I want to thank Evan Shelhamer, who mentored me during my internship at Adobe Research, and has been giving continued support throughout the rest of my Ph.D. I am also grateful to Saining Xie for giving me the opportunity for an internship at Facebook AI Research and guided me through the research project. I want to thank Hanzi Mao for her crucial help in this project too. Additionally, I am thankful to Junyan Zhu and Tinghui Zhou who mentored me as senior students in my earlier Ph.D. years. 
% , which also led to my first full-time job as a Research Scentist at FAIR after my Ph.D. journey.

I am also grateful to my research mentors and collaborators before I came to Berkeley. It was in Prof. Kilian Weinberger's group at Cornell University that I started my journey in the field of deep learning, during my visit there in 2016. I want to thank Gao Huang, Yu Sun and Shuang Li who helped me learn the basics of deep learning research there. I would like to thank Jianguo Li for taking me as a research intern at Intel Labs China when I was a senior undergraduate, and the great mentorship he gave. I'm also grateful to Prof. Andrew Yao, who built the undergraduate program at Tsinghua that led me into the world of computer science. I want to thank Shiquan Wang, Farong Zhou, Huijuan Wang, Niya Wei and all my other teachers since childhood who committed their lives into the education of next generations.

My gratitude goes to my other collaborators, colleagues and friends, at Berkeley or otherwise. I want to thank Bingyi Kang, Chubai Chen, Guanhua Wang, Zhiqiang Shen, Xiang Gao, 
Xuanlin Li, Mingjie Sun, Hung-Ju Wang, Zhiqiu Xu, Joseph Jin, Maolin Mao, Yinbo Chen, Brandon Hsieh, 
Yi Wu, Yang Gao, Yang You, Bichen Wu, Dequan Wang, Huazhe Xu, Xin Wang, Xiangyu Yue, Shizhan Zhu, Zhe Cao, Haozhi Qi, Hang Gao, Wenlong Mou, Zihao Chen, 
Xingyi Zhou, Hexiang Hu, Hengshuang Zhao, Zhipeng Cai, Yixing Lao, Ji Lin, Linnan Wang, 
Christoph Feichtenhofer, Chao-Yuan Wu, Chuan Guo, Huijuan Xu, Xiaolong Wang, Fisher Yu, Deepak Pathak,
 Kai Jin, Lihan Zhu, Rui Li, Cheng Zhu and Zijing Xia.
 I am thankful to Jiashi Feng, Qixing Huang, Jingdong Wang, Xiaoming Liu, Zhuowen Tu, Ng Teck Khim, who as senior members of the research community gave me many advices. I want to thank other members of Prof. Trevor Darrell's lab for building such a wonderful and supportive group.

 I would like to thank my partner Chen Zhang, who has been the source of happiness, comfort and encouragement in my life. I look forward to starting the next chapter of my life with you.


Finally, I would like to thank my parents Lilin Miao and Qing Liu, and my grandparents, Fangcui Wang and Nengyuan Miao. You gave me myself, my life, and a family with love. Without your support all the way since my birth and childhood, I could not imagine myself getting a Ph.D.

% values  Of courses, the lessons are more than just on academic research. He encouraged me when there 

% During my Ph.D., I am also for


\end{acknowledgements}

\end{frontmatter}

\pagestyle{headings}

\chapter{Introduction}

% history of deep learning

% briefly computer vision and visual recognition
% moving from hand crafted features to deep learning

% architectures: important. steady stream of architecture research:

% what do people care about architecture.

% briefly mention NAS

% Transformers: resurgence of architecture research.

% Deep learning architecture is fundamental. 


\section{Thesis Organization}
% organization layout


\graphicspath{ {./anytime_figures/} }
\include{chap2}

\graphicspath{ {./rethinking_figures/} }
\include{chap3}

\graphicspath{ {./convnext_figures/} }
\include{chap4}

\chapter{Discussions}
In conclusion, this thesis presents three works that either proposes an new architectural framework or study existing architectures for visual recognition applications. In Chapter 

\section{Future Works}
\subsection{Studying Inductive Biases}
Just as Chapter~\ref{chap:convnext} demonstrated, the comparison between ConvNets and Transformers are often conflated with detailed architecture specifications, thus leading to an underestimation of ConvNets' potential. In our work, ConvNeXts are mainly compared with Swin-Transformers, not vanilla ViTs. Swin-Transformer still differ from ViTs in that they incorporate \emph{hierarchical features}, \emph{local computation}. 

The debate between ConvNets \vs Transformers are sometimes 

\subsection{Self-Supervised Learning}
All results in this dissertation 

\subsection{Multi-modal Learning}


While there is promise to build a unified AI system that handles a variety of tasks, potentially using Transformers, we believe different architectures could still thrive together. Such a giant model may not 


\section{Closing Remarks}
There has been an interesting debate in the AI community on the question ``Is scaling all you need?''. 

There are 

The question is, 




\printbibliography
\end{document}
